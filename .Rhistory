movieMaker(x, departments)
pb$tick()
}
ticks = length(ids)
ticks
pb = progress::progress_bar$new(total = ticks)
movies = list()
progress_function = function(x, departments){
movieMaker(x, departments)
pb$tick()
}
ticks = length(ids)
pb = progress::progress_bar$new(total = ticks)
tic()
movies = furrr::future_map(ids, function(x){
tryCatch({
progress_function(x,departments), error = function(e){})
})
toc()
progress_function = function(id, departments){
movieMaker(id, departments)
pb$tick()
}
ticks = length(ids)
pb = progress::progress_bar$new(total = ticks)
tic()
movies = furrr::future_map(ids, function(x){
tryCatch({
progress_function(x,departments), error = function(e){})
})
toc()
progress_function = function(x, departments){
movieMaker(x, departments)
pb$tick()
}
ticks = length(ids)
pb = progress::progress_bar$new(total = ticks)
tic()
movies = furrr::future_map(ids, function(x){
tryCatch({
progress_function(x,departments)}, error = function(e){})
})
toc()
ticks = length(ids)
pb = progress::progress_bar$new(total = ticks)
movies = list()
movies = furrr::future_map(ids, function(x){
\
movies = furrr::future_map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
})
i=1
movies = furrr::future_map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
print(i)
i = i+1
})
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for multithreading
library(parallel)
parallel::detectCores()
plan(multisession(workers = 10))
select = dplyr::select
PATH = getwd()
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'tmdb_keys.R'))
source(file.path(SCRIPTS_PATH, 'tmdb_helpers.R'))
ids = getTMDbIDs(n=1000)
movies = list()
tic()
movies = furrr::future_map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
})
toc()
t = 39.77
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for multithreading
library(parallel)
parallel::detectCores()
plan(multisession(workers = 10))
select = dplyr::select
PATH = getwd()
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'tmdb_keys.R'))
source(file.path(SCRIPTS_PATH, 'tmdb_helpers.R'))
ids = getTMDbIDs(n=1000)
movies = list()
tic()
movies = purrr::map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
})
toc()
View(movies)
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for multithreading
library(parallel)
parallel::detectCores()
plan(multisession(workers = 10))
select = dplyr::select
PATH = getwd()
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'tmdb_keys.R'))
source(file.path(SCRIPTS_PATH, 'tmdb_helpers.R'))
ids = getTMDbIDs(n=6000)
movies = list()
tic()
movies = purrr::map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
})
toc()
92*6
movies = list()
tic()
movies = furrr::future_map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
})
toc()
movies = bind_rows(movies)
View(movies)
write.csv(file.path(DATA_PATH, 'scrape_data.csv'), row.names = F)
file.path(DATA_PATH, 'scrape_data.csv')
write.csv(movies, file.path(DATA_PATH, 'scraped_data.csv'), row.names = F)
R.home()
getwd()
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for multithreading
library(parallel)
parallel::detectCores()
plan(multisession(workers = 10))
select = dplyr::select
PATH = getwd()
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'tmdb_keys.R'))
source(file.path(SCRIPTS_PATH, 'tmdb_helpers.R'))
ids = getTMDbIDs(n=6000)
movies = list()
install.packages(cronR)
install.packages('cronr')
install.packages('cronR')
library(cronR)
cronR::cron_ls()
ids = ids[1:100]
tic()
movies = furrr::future_map(ids, function(x){
tryCatch({
movieMaker(x,departments)}, error = function(e){})
})
toc()
movies = bind_rows(movies)
movies$bag_of_words = paste(movies$Directing, movies$genres, movies$production_companies,
movies$keywords, movies$cast)
write.csv(movies, file.path(DATA_PATH, 'scraped_data.csv'), row.names = F)
getwd()
cronR::cron_ls()
?memory
?Memory
1:10
a <- 1:10
b = c(1,2,3,4,5,6,7,8,9,10)
a==b
c = b
c==b
mean(a)
base::mean(a)
get(mean)
get(a, mean)
get("mean")
install.packages('lobstr')
install.packages('lobstr', type = 'source')
library(lobstr)
mean
base::mean
get("mean")
evalq(mean)
match.fun(mean)
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, warning = FALSE, message = FALSE)
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for parallelisation
library(parallel)
parallel::detectCores(logical = TRUE) #determine total cores available
future::plan(multisession(workers = 10)) #Can be adjusted based on machine. Can also be adjusted to just use however much CPU power is available.
select = dplyr::select
`%notin%` = Negate(`%in%`)
future::plan(multisession(workers = 4)) #Can be adjusted based on machine. Can also be adjusted to just use however much CPU power is available.
select = dplyr::select
`%notin%` = Negate(`%in%`)
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for parallelisation
library(parallel)
parallel::detectCores(logical = TRUE) #determine total cores available
future::plan(multisession(workers = 10)) #Can be adjusted based on machine. Can also be adjusted to just use however much CPU power is available.
select = dplyr::select
`%notin%` = Negate(`%in%`)
library(TMDb)
library(dplyr)
library(readr)
library(tictoc)
library(furrr) #for parallelisation
library(parallel)
parallel::detectCores(logical = TRUE) #determine total cores available
future::plan(multisession(workers = 4)) #Can be adjusted based on machine. Can also be adjusted to just use however much CPU power is available.
select = dplyr::select
`%notin%` = Negate(`%in%`)
getTMDbIDs = function(n = 6000, verbose = FALSE){
pages = seq(1,n/20, by = 1) #20 ids per page so n/20 = number of pages to look at
results = list() #by default results are returned as a list item so there is a need for a bit of housekeeping
for(i in 1:max(pages)){
results[[i]] = discover_movie(api_key, language = 'en', sort_by = 'vote_count.desc', page = i)$results$id
if(verbose = TRUE){
getTMDbIDs = function(n = 6000, verbose = FALSE){
pages = seq(1,n/20, by = 1) #20 ids per page so n/20 = number of pages to look at
results = list() #by default results are returned as a list item so there is a need for a bit of housekeeping
for(i in 1:max(pages)){
results[[i]] = discover_movie(api_key, language = 'en', sort_by = 'vote_count.desc', page = i)$results$id
if(verbose == TRUE){
print(i)
}
}
ids = unlist(results) #convert from list back to vector of ids
return(ids) #I think that last step could be optimzed but I wrote this way back when and don't care abotu fixing it.
}
getTMDbIDs = function(n = 6000, verbose = FALSE){
pages = seq(1,n/20, by = 1) #20 ids per page so n/20 = number of pages to look at
results = list() #by default results are returned as a list item so there is a need for a bit of housekeeping
for(i in 1:max(pages)){
results[[i]] = discover_movie(api_key, language = 'en', sort_by = 'vote_count.desc', page = i)$results$id
if(verbose == TRUE){
print(i)
}
}
ids = unlist(results) #convert from list back to vector of ids
return(ids) #I think that last step could be optimzed but I wrote this way back when and don't care abotu fixing it.
}
getTMDbIDs(n = 500)
PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'tmdb_keys.R'))
getwd()
#PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
PATH = getwd()
#PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
PATH = getwd()
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'tmdb_keys.R'))
source(file.path(SCRIPTS_PATH, 'tmdb_helpers.R'))
getTMDbIDs(n = 500)
ids = getTMDbIDs(n = 500)
movieMaker = function(id){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
return(m)
}
movieMaker(ids[1])
str(movieMaker(ids[1]))
m = movieMaker(ids[1])
str(m)
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name #collapse dataframe column down to a single vector.
return(df)
}
str(m[1:4])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name #collapse dataframe column down to a single vector.
return(df)
}
str(m[1:8])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name #collapse dataframe column down to a single vector.
return(df)
}
str(df[1:8])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name #collapse dataframe column down to a single vector.
return(df)
}
str(df)
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name #collapse dataframe column down to a single vector.
return(df)
}
m = movieMaker(ids[1])
str(m[1:5])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name #collapse dataframe column down to a single vector.
return(df)
}
m = movieMaker(ids[1])
str(m[1:6])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name
df$production_companies = m$production_companies$name
df$production_countries = m$production_countries$name
df$belongs_to_collection = NULL
df$spoken_languages = m$spoken_languages$english_name
df$cast = m$credits$cast[m$credits$cast$order %in% sort(head(m$credits$cast$order, 6)),]$name
df$crew = m$credits$crew
df$credits = NULL
df$keywords = m$keywords$keywords$name
return(df)
}
m = moviMaker(ids[1])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name
df$production_companies = m$production_companies$name
df$production_countries = m$production_countries$name
df$belongs_to_collection = NULL
df$spoken_languages = m$spoken_languages$english_name
df$cast = m$credits$cast[m$credits$cast$order %in% sort(head(m$credits$cast$order, 6)),]$name
df$crew = m$credits$crew
df$credits = NULL
df$keywords = m$keywords$keywords$name
return(df)
}
m = movieMaker(ids[1])
str(m[1:10])
movieMaker = function(id, departments){
m = movie(api_key, id, append_to_response = c("credits, keywords"))
df = m
df$genres = m$genres$name
df$production_companies = m$production_companies$name
df$production_countries = m$production_countries$name
df$belongs_to_collection = NULL
df$spoken_languages = m$spoken_languages$english_name
df$cast = m$credits$cast[m$credits$cast$order %in% sort(head(m$credits$cast$order, 6)),]$name
df$crew = m$credits$crew
df$credits = NULL
df$keywords = m$keywords$keywords$name
return(df)
}
m = movieMaker(ids[1])
str(m)
library(reticulate)
select = dplyr::select
PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
reticulate::source_python(file.path(SCRIPTS_PATH, 'py_similarity.py'))
titles = read.csv(file.path(DATA_PATH, 'scraped_data.csv'))
reticulate::repl_python()
library(reticulate)
select = dplyr::select
PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
reticulate::source_python(file.path(SCRIPTS_PATH, 'py_similarity.py'))
titles = read.csv(file.path(DATA_PATH, 'scraped_data.csv'))
titles = titles$original_title
m = cosine_matrix()
rownames(m) = titles
colnames(m) = titles
m
PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(SCRIPTS_PATH, 'similarity.R'))
streaming = read.csv(file.path(PATH, 'data/streaming.csv'), stringsAsFactors = F) %>% mutate(Netflix = ifelse(is.na(Netflix), "", Netflix),
hulu = ifelse(is.na(hulu), "", hulu),
amazon = ifelse(is.na(amazon), "", amazon),
disney = ifelse(is.na(disney), "", disney),
hbo = ifelse(is.na(hbo), "", hbo),
apple = ifelse(is.na(apple), "", apple),
criterion = ifelse(is.na(criterion), "", criterion),
services = paste0(Netflix, " ", hulu, " ", amazon, " ", disney, " ", hbo, " ", apple, " ", criterion)) %>%
select(Title, services)
library(dplyr)
library(dplyr)
PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(SCRIPTS_PATH, 'similarity.R'))
streaming = read.csv(file.path(PATH, 'data/streaming.csv'), stringsAsFactors = F) %>% mutate(Netflix = ifelse(is.na(Netflix), "", Netflix),
hulu = ifelse(is.na(hulu), "", hulu),
amazon = ifelse(is.na(amazon), "", amazon),
disney = ifelse(is.na(disney), "", disney),
hbo = ifelse(is.na(hbo), "", hbo),
apple = ifelse(is.na(apple), "", apple),
criterion = ifelse(is.na(criterion), "", criterion),
services = paste0(Netflix, " ", hulu, " ", amazon, " ", disney, " ", hbo, " ", apple, " ", criterion)) %>%
select(Title, services)
gimme_something_to_watch = function(movie){
if(movie %in% titles){
return(attr(head(sort(m[movie,], decreasing = T),20), "names"))
} else{
return("We don't have that movie in our database...Check your spelling/special characters and try again.")
}
}
join_results = function(movie){
t = gimme_something_to_watch(movie) %>% as.data.frame()
t = as.data.frame(t[-1,])
colnames(t) = "Title"
rownames(t) = NULL
return(left_join(t,streaming) %>% mutate(services = ifelse(is.na(services), " ", services)))
}
#!/usr/bin/env Rscript
#cd 'box sync'/'box sync'/'python codes'/movie_rec_twitter
#Twitter Bot
library(twitteR)
library(rvest)
library(jpeg)
library(rtweet)
library(stringr)
library(gridExtra)
'%notin%' = Negate('%in%')
`%notin%` = Negate(`%in%`)
PATH = "/home/mwhalen18/Dropbox (University of Michigan)/R Projects/MovieRecommender"
SCRIPTS_PATH = file.path(PATH, 'scripts')
KEYS_PATH = file.path(PATH, 'scripts/keys')
DATA_PATH = file.path(PATH, 'data')
source(file.path(KEYS_PATH, 'twitter_keys.R'))
source(file.path(SCRIPTS_PATH, "stream_scrape_join.R"))
#need both rtweet and twitteR
#rtweet::create_token(consumer_key = api_key,
#                     consumer_secret = api_secret,
#                     access_token = access_token,
#                     access_secret = access_secret)
options(httr_oauth_cache = TRUE)
setup_twitter_oauth(consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret)
mentioners = rtweet::get_mentions() #again, need them both
KEYS_PATH
mentioners = rtweet::get_mentions() #again, need them both
auth_setup_default()
mentioners = rtweet::get_mentions() #again, need them both
mentioners
mention= mentions() #really, the only reason is why the fuck doesn rtweet give you the username of the tweeter?????? There's gotta be a way but I can't figure it out
mention
ids = pull(read.csv("files/replied_to_ids.txt", header = F, stringsAsFactors = F,numerals = "no.loss"))
ids
for(i in seq_along(mention)){ #loop along every element in the list of current mentions
failure = "We don't have that movie in our database...Check your spelling/special characters and try again."
if(mention[[i]]$getId() %notin% ids){ #only run this on tweet ids that we have not already responded to
handle = paste("@", mention[[i]]$getScreenName(),sep = "") #create a handle string for the individual we hope to reply to
id = mention[[i]]$getId() #pull out the id for the tweet id
ids = append(ids, id)
if(str_detect(mention[[i]]$text, "recommend")){ #if our string has our special call word
text = mention[[i]]$text #pull out the text of our mention to analyze
movie = sub(".*recommend ", "", text) #just get the movie title
df = join_results(movie) #run our function and assign it to a frame
if(df[1] == failure){
message = paste(handle, "Uh oh! It looks like we don't have that in our database. Check your spelling/punctuation and try again.")
post_tweet(status = message, in_reply_to_status_id = mentioners[i,]$status_id)
} else{
jpeg("temp.jpeg", height = 25*nrow(df), width = 350) #the next few lines just prepare R to store the table as a temprary JPEG
grid.table(df)
dev.off() #this line saves a temporary JPEG
message = paste(handle, "Here are my recommendations. Enjoy!")
rtweet::post_tweet(status = message, media = "temp.jpeg", in_reply_to_status_id = mentioners[i,]$status_id)
}
} else{
message = paste(handle, "Use the key word 'recommend' followed by the title of a movie to activate me.")
post_tweet(message, in_reply_to_status_id = mentioners[i,]$status_id)
}
}
}
auth_setup_default()
